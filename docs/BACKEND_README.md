# Resume Analyzer Backend

## ğŸ—ï¸ Architecture Overview

The Resume Analyzer backend is built with **Python FastAPI** and follows a modular microservices architecture for scalable resume analysis and processing.

## ğŸš€ Tech Stack

### Core Framework

- **FastAPI** - High-performance async web framework
- **Uvicorn** - ASGI server for production deployment
- **Python 3.8+** - Core programming language

### Document Processing

- **PyMuPDF** - High-performance PDF text extraction
- **python-docx** - Microsoft Word document parsing
- **PyPDF2** - Fallback PDF processing

### AI & Analysis

- **Google Gemini AI** - Advanced resume analysis and insights
- **Groq API** - Fast LLM inference for text processing
- **Custom ML Models** - ATS compatibility scoring

### Data Processing

- **JSON** - Structured data exchange
- **Regex** - Pattern matching and text extraction
- **Custom Parsers** - Domain-specific resume parsing

## ğŸ“ Module Structure

```
python_scripts/
â”œâ”€â”€ final_api.py           # ğŸ¯ Main API orchestration
â”œâ”€â”€ document_parser.py     # ğŸ“„ Document processing coordinator
â”œâ”€â”€ pdf_parser.py         # ğŸ“• PDF text extraction
â”œâ”€â”€ docx_parser.py        # ğŸ“˜ Word document parsing
â”œâ”€â”€ section_detector.py   # ğŸ” Resume section identification
â”œâ”€â”€ text_normalizer.py    # ğŸ§¹ Text cleaning and formatting
â”œâ”€â”€ info_extractor.py     # ğŸ“Š Structured data extraction
â”œâ”€â”€ ats_analyzer.py       # ğŸ¤– ATS compatibility analysis
â”œâ”€â”€ quality_scorer.py     # â­ Resume quality assessment
â”œâ”€â”€ gemini_analyzer.py    # ğŸ§  AI-powered insights
â””â”€â”€ feedback_report.py    # ğŸ“‹ Report generation
```

## ğŸ”„ Processing Flow

### 1. **Document Upload & Validation**

```
fastapi_server.py â†’ File validation â†’ Temporary storage
```

### 2. **Document Parsing Pipeline**

```
final_api.py â†’ document_parser.py â†’ [pdf_parser.py | docx_parser.py]
```

### 3. **Text Processing & Normalization**

```
Raw text â†’ text_normalizer.py â†’ Clean, formatted text
```

### 4. **Section Detection & Structure Analysis**

```
Normalized text â†’ section_detector.py â†’ Identified sections
```

### 5. **Information Extraction**

```
Structured sections â†’ info_extractor.py â†’ Contact, Skills, Experience, etc.
```

### 6. **Multi-Layered Analysis**

```
Extracted data â†’ [ats_analyzer.py, quality_scorer.py, gemini_analyzer.py]
```

### 7. **Report Generation**

```
Analysis results â†’ feedback_report.py â†’ Comprehensive JSON response
```

## ğŸ¯ Core Components

### **final_api.py** - API Orchestration

- **Purpose**: Main entry point for resume analysis
- **Features**:
  - Input validation and error handling
  - Coordinates entire analysis pipeline
  - Standardized JSON response formatting
- **Key Functions**:
  - `analyze_resume_api()` - Main analysis endpoint

### **document_parser.py** - Document Processing

- **Purpose**: Orchestrates document parsing and analysis
- **Features**:
  - Multi-format support (PDF, DOCX)
  - Integrated analysis pipeline
  - Error handling and fallbacks
- **Dependencies**: All parsing and analysis modules

### **Text Processing Modules**

#### **pdf_parser.py**

- **Tech**: PyMuPDF, PyPDF2
- **Features**:
  - High-performance PDF text extraction
  - Metadata extraction
  - Scanned document detection

#### **docx_parser.py**

- **Tech**: python-docx
- **Features**:
  - Word document parsing
  - Table and formatting preservation
  - Metadata extraction

#### **text_normalizer.py**

- **Purpose**: Text cleaning and standardization
- **Features**:
  - Unicode normalization
  - Whitespace cleanup
  - Special character handling

### **Analysis Modules**

#### **section_detector.py**

- **Purpose**: Resume section identification
- **Algorithm**: Pattern-based ML detection
- **Sections**: Contact, Summary, Experience, Education, Skills, etc.

#### **info_extractor.py**

- **Purpose**: Structured data extraction
- **Features**:
  - Contact information parsing
  - Experience timeline analysis
  - Skills categorization
  - Education details extraction

#### **ats_analyzer.py**

- **Purpose**: ATS (Applicant Tracking System) compatibility
- **Analysis**:
  - Keyword optimization
  - Format compatibility
  - Parsing friendliness scoring
  - Industry standards compliance

#### **quality_scorer.py**

- **Purpose**: Comprehensive quality assessment
- **Scoring Categories**:
  - Content completeness (25%)
  - Professional presentation (25%)
  - Skills relevance (25%)
  - Experience quality (25%)

#### **gemini_analyzer.py**

- **Tech**: Google Gemini AI API
- **Purpose**: AI-powered insights and recommendations
- **Features**:
  - Intelligent content analysis
  - Personalized recommendations
  - Industry-specific insights
  - Career progression analysis

#### **feedback_report.py**

- **Purpose**: Comprehensive report generation
- **Output**: Structured JSON with 30+ analysis categories

## ğŸ”Œ API Endpoints

### **FastAPI Server** (`../fastapi_server.py`)

#### `GET /`

- **Purpose**: Health check and API information
- **Response**: Service status and feature list

#### `GET /health`

- **Purpose**: Deployment monitoring
- **Response**: Health status

#### `POST /analyze-resume`

- **Purpose**: Complete resume analysis
- **Parameters**:
  - `file` (required) - Resume file (PDF/DOCX)
  - `job_title` (optional) - Target job title
  - `job_description` (optional) - Job posting text
  - `target_skills` (optional) - Required skills list
- **Response**: Comprehensive analysis JSON

## ğŸ“Š Response Structure

```json
{
  "status": "success|error",
  "status_code": 200|400|500,
  "message": "Description",
  "data": {
    "contact_info": {...},
    "education": [...],
    "experience": [...],
    "skills": {...},
    "ats_analysis": {...},
    "quality_analysis": {...},
    "ai_insights": {...},
    "recommendations": [...],
    // ... 30+ analysis categories
  }
}
```

## ğŸš€ Deployment

### **Local Development**

```bash
# Install dependencies
pip install -r ../requirements.txt

# Start FastAPI server
uvicorn fastapi_server:app --reload --host 0.0.0.0 --port 8000
```

### **Production**

```bash
# With Uvicorn (recommended)
uvicorn fastapi_server:app --host 0.0.0.0 --port 8000 --workers 4

# With Gunicorn
gunicorn fastapi_server:app -w 4 -k uvicorn.workers.UvicornWorker
```

### **Environment Variables**

```env
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com
GOOGLE_API_KEY=your_gemini_api_key
GROQ_API_KEY=your_groq_api_key
```

## ğŸ”§ Configuration

### **CORS Settings**

- Configurable origins for frontend integration
- Supports multiple domains for deployment flexibility

### **File Processing Limits**

- Max file size: 10MB
- Supported formats: PDF, DOCX, DOC
- Timeout: 30 seconds per analysis

### **AI Integration**

- Gemini AI for advanced analysis
- Groq for fast text processing
- Fallback mechanisms for API failures

## ğŸ›¡ï¸ Security & Performance

### **Security Features**

- File type validation
- Size limits and timeouts
- CORS protection
- Input sanitization

### **Performance Optimizations**

- Async processing with FastAPI
- Efficient PDF parsing with PyMuPDF
- Modular architecture for scalability
- Response caching potential

### **Error Handling**

- Comprehensive error responses
- Graceful fallbacks for AI services
- Detailed logging for debugging

## ğŸ”„ Future Enhancements

### **Planned Features**

- Batch processing support
- Real-time analysis updates
- Enhanced AI model integration
- Performance metrics and monitoring

### **Scalability Considerations**

- Microservices architecture ready
- Database integration capability
- Queue-based processing potential
- Docker containerization support

---

## ğŸ“ Support

For backend-specific issues:

1. Check logs in FastAPI console
2. Verify Python dependencies
3. Confirm API key configurations
4. Test individual modules independently

**Backend Entry Point**: `../fastapi_server.py`  
**Main API Logic**: `final_api.py`  
**Module Documentation**: Each module contains detailed docstrings
